<html>

<head>
	<meta http-equiv="Content-Type" content="text/html;charset=utf-8">
	<title>Analysis report</title>
</head>

<body>
	<h1 id="top">Results</h1>

	<table border="1" cellspacing="0" cellpadding="5">
		<tr>
			<th rowspan=2>Algorithms</th>
			<th colspan=4>Estimated number of clusters</th>
		</th>
		<tr>
			<th>Gap statistic</th>
			<th>Silhouette score</th>
			<th>Davies-Bouldin score</th>
			<th>Calinski and Harabasz score</th>
		</tr>

	{%- for algorithm in algorithms %}
		<tr>
			<td><a href="#{{ algorithm.name }}">{{ algorithm.name }}</a></td>
			<td>{{ algorithm.results['gap_nc'] }}</td>
			<td>{{ algorithm.results['silhouette_nc'] }}</td>
			<td>{{ algorithm.results['davies_nc'] }}</td>
			<td>{{ algorithm.results['calinski_nc'] }}</td>
		</tr>
	{%- endfor %}
	</table>
	<p>
	According to the majority rule, the estimated number of clusters is <strong>{{ nc }}</strong>.
	</p>
	<br>

	<h2>Clustering <font size="-1">[<a href="#top">Back To Top</a>]</font></h2>
	<p>
		<ul>
			<li>Clustering is the task of <strong>grouping a set of data samples in such a way that samples in the same group are more similar to each other</strong> than to those in other groups.</li>
			<li>In general, data samples have no labels so that we <strong>need to interpret the results of clustering</strong>.</br>
			    This type of problems are called <string>unsupervised learning</strong>.
			</li>
			<li>Many clustering algorithms <strong>need to set the number of clusters</strong> in advance.</br>
			    However, the optimal number of clusters is unknown.</br>
				Therefore, MALSS conducts the cluster analysis with a range of candidates of the number of clusters.
			</li>
			<li>A wide variety of indices have been proposed to find the optimal number of clusters.</br>
			    MALSS <strong>estimates the optimal number of clusters by majority vote</strong> of these indices.
			</li>
			<li>The indices that MALSS uses are as follows: 
			    <a href="https://statweb.stanford.edu/~gwalther/gap" target="new">Gap statistic</a>，
				<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" target="new">Silhouette score</a>，
				<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html" target="new">Davies-Bouldin score</a>，
				<a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html" target="new">Calinski and Harabasz score</a>.
			</li>
		</ul>
	</p>
	<hr>

	<h2>Data summary <font size="-1">[<a href="#top">Back To Top</a>]</font></h2>
	<ul>
		<li>Number of rows: {{ data.shape_before[0] }}</li>
		<li>Number of columns: {{ data.shape_before[1] }} (numerical: {{ data.shape_before[1] - data.del_columns|length }}, categorical: {{ data.del_columns|length }})</li>
		{%- if data.del_columns|length > 0 %}
		<ul>
			<li>Categorical values were encoded to integer features using a <a href="http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features">one-of-K scheme</a>.</li>
		</ul>
		{%- endif %}
		{%- if data.col_was_null|length > 0 %}
		<li>Column {% for col in data.col_was_null %}{{ col }} {% endfor %}had NA values.</li>
		<ul>
			<li>NA values were filled in with the most frequent value (categorical), median (integer), mean (float).</li>
			<li>See also: <a href="http://pandas.pydata.org/pandas-docs/stable/missing_data.html">missing data</a></li>
		</ul>
		{%- endif %}
	</ul>
	<details>
	<summary><font size="+1"><strong>Descriptions (click here)</strong></font></summary>
	<ul>
		<li>Clustering algorithms are affected by the difference of the scale of each attributes.</br>
		    <strong>If the scale of an attribute is much smaller than that of the other attributes</strong> (e.g. the attribute has one digit and the other attributes have five digits.), <strong>the effect of the attribute is ignored</strong>.</br>
			Therefore, <strong>MALSS standardizes the data</strong> to a mean is zero and standard deviation is one by default.</br>
			If scaling is not needed, set <i>standardize</i> parameter to <i>True</i>.
		<li>Note that some features (e.g. country code) may have to be handled as the categorical feature even though they look like numerical features. In such case, you need to encode categorical features into numerical features using a <a href="http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features">one-of-K scheme</a> by yourself before setting data to MALSS.</li>
	</ul>
	</details>
	<hr>

	<h2 id="{{ algorithms[0].name }}"><a href="{{ algorithms[0].link }}">k-means clustering</a> <font size="-1">[<a href="#top">Back To Top</a>]</font></h2>
	<p>
		<ul>
			<li><a href="https://en.wikipedia.org/wiki/K-means_clustering" target="new">k-means clustering</a> is one of the most commonly used clustering algorithm.</li>
			<li>Note that k-means algorithm assumes that clusters are spherical and of equal size.</br>
			    If clusters are not spherical or not of equal size, k-means algorithm may produce undesirable results.
			</li>
		</ul>
	</p>

	<h3>Gap statistics</h3>
	<img border="0" src="gap_{{ algorithms[0].estimator.__class__.__name__ }}.png" height="300" alt="gap_statistics">

	<h3>Silhouette score</h3>
	<img border="0" src="silhouette_{{ algorithms[0].estimator.__class__.__name__ }}.png" height="300" alt="silhouette_score">
    
	<h3>Davies-Bouldin score</h3>
	<img border="0" src="davies_{{ algorithms[0].estimator.__class__.__name__ }}.png" height="300" alt="davies_bouldin_score">
    
	<h3>Calinski and Harabasz score</h3>
	<img border="0" src="calinski_{{ algorithms[0].estimator.__class__.__name__ }}.png" height="300" alt="calinski_harabasz_score">
    
	<h2 id="{{ algorithms[1].name }}"><a href="{{ algorithms[1].link }}">Hierarchical clustering</a> <font size="-1">[<a href="#top">Back To Top</a>]</font></h2>
	<p>
		<ul>
			<li><a href="https://en.wikipedia.org/wiki/Hierarchical_clustering" target="new">Hierarchical clustering</a> is one of the most commonly used clustering algorithm as well as k-means algorithm.</li>
			<li>Hiearchical clustering algorithms are broadly devided into two groups.</br>
			    One is <strong>agglomerative (bottom-up) approach</strong> that each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.</br>
				The other is <strong>divisive (top-down) approach</strong> that all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.</br>
				MALSS supports agglomerative clustering methods.
			</li>
			<li>Hierarchical clustering algorithms have an advantage that they can visualize the results of clustering as a cluster tree called <strong>dendrogram</strong>.</br>
			    Note the following points when referring the dendrogram:
				<ul>
					<li><strong>Proximity along the horizontal axis of the dendrogram doesn't represent the similarity of two observations</strong>.</br>
					    We need to see the location on the vertical axis where branches containing those two observations first are fused.
					</li>
					<li><strong>The assumption that an arbitrary data has hierarchical structure might be unrealistic</strong> though the results of hierarchical clustering always have hierarchical structures.</li>
					<li>Dendrogram strongly depends on the type of <a href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.linkage.html" target="new">linkage</a>, which defines the dissimilarity between two groups of observations.</br>
					    MALSS adopts a <i>complete linkage method</i>.
					</li>
				</ul>
			</li>
		</ul>
	</p>

	<h3>Dendrogram</h3>
	<img border="0" src="dendrogram_{{ algorithms[1].estimator.__class__.__name__ }}.png" height="400" alt="dendrogram">

	<h3>Gap statistics</h3>
	<img border="0" src="gap_{{ algorithms[1].estimator.__class__.__name__ }}.png" height="300" alt="gap_statistics">

	<h3>Silhouette score</h3>
	<img border="0" src="silhouette_{{ algorithms[1].estimator.__class__.__name__ }}.png" height="300" alt="silhouette_score">
    
	<h3>Davies-Bouldin score</h3>
	<img border="0" src="davies_{{ algorithms[1].estimator.__class__.__name__ }}.png" height="300" alt="davies_bouldin_score">
    
	<h3>Calinski and Harabasz score</h3>
	<img border="0" src="calinski_{{ algorithms[1].estimator.__class__.__name__ }}.png" height="300" alt="calinski_harabasz_score">
    
</body>
</html>
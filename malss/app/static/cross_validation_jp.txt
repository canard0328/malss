過学習を防ぐためには<strong>データを増やす</strong>ことが効果的です。<br>
また，機械学習アルゴリズムのなかには，過学習しにくくするためのハイパーパラメータ（<font color="#1E90FF"><strong>正則化パラメータ</strong></font>）を持つものもあります。<br>
<br>
それでは，過学習しているかを，手元のデータだけからどのように確認すればよいでしょうか。<br>
そのためには，<font color="#1E90FF"><strong>交差検証</strong></font>（Cross validation）という手法がよく用いられます。<br>
手元のデータをk個に分割し，そのうちのk-1個分のデータを手元のデータとして学習用に，残りを未知のデータとして評価用にします。<br>
そして，未知のデータとして扱うデータを変更しながら学習，評価をk回くり返し，評価結果の平均値を未知のデータに対する性能の推定値とします。この手法を<strong>k分割交差検証</strong>（k-fold cross validation）と呼びます。